{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Dimensionality Analysis\n",
    "\n",
    "Using the Standard Background Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET = \"./dataset\"\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class labels\n",
    "class_dict = pd.read_csv(os.path.join(DATASET, \"labels_class_dict.csv\"))\n",
    "class_names = class_dict['class_names'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset metadata\n",
    "metadata = pd.read_csv(os.path.join(DATASET, \"metadata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Augmentation Pipeline using Albumentations\n",
    "def get_train_augmentations():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=30, p=0.5),  # Random rotation up to Â±30 degrees\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "    ])\n",
    "\n",
    "train_augmentations = get_train_augmentations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(metadata_df, dataset_path, augment=False):\n",
    "    images, masks = [], []\n",
    "    \n",
    "    for _, row in metadata_df.iterrows():\n",
    "        img_path = os.path.join(dataset_path, row[\"image_path\"])\n",
    "        mask_path = os.path.join(dataset_path, row[\"label_colored_path\"])  \n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Warning: Mask not found for {row['image_path']}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Failed to load image {row['image_path']}, skipping...\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"Warning: Failed to load mask {row['label_colored_path']}, skipping...\")\n",
    "            continue\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Apply augmentation if enabled\n",
    "        if augment:\n",
    "            augmented = train_augmentations(image=img, mask=mask)\n",
    "            img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        img = img / 255.0  # Normalize image to [0, 1]\n",
    "        mask = mask.astype(np.uint8)  # Ensure mask is integer\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation datasets\n",
    "X_train, y_train = load_data(metadata, DATASET, augment=True)\n",
    "X_val, y_val = load_data(metadata, DATASET, augment=False)  # No augmentation for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize class labels to start from 0\n",
    "unique_labels = np.unique(y_train)\n",
    "label_mapping = {old_label: idx for idx, old_label in enumerate(unique_labels)}\n",
    "y_train = np.vectorize(label_mapping.get)(y_train).astype(np.int32)\n",
    "y_val = np.vectorize(label_mapping.get)(y_val).astype(np.int32)\n",
    "\n",
    "# Ensure the correct shape (batch_size, height, width, 1)\n",
    "y_train = y_train.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "y_val = y_val.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "\n",
    "NUM_CLASSES = len(unique_labels)  # Use correct number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Print dataset information\n",
    "print(f\"Dataset loaded: {len(X_train)} training images, {len(X_val)} validation images\")\n",
    "print(f\"Shape of X_train: {X_train.shape}, Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Remapped unique values in y_train: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Show a random image and its mask before training\n",
    "index = np.random.randint(0, len(X_train))\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train[index])\n",
    "plt.title(\"Sample Image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y_train[index].squeeze(), cmap=\"jet\")\n",
    "plt.title(\"True Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape=(256, 256, 3), num_classes=NUM_CLASSES):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    # Decoder with Skip Connections\n",
    "    u1 = layers.UpSampling2D((2, 2))(c4)\n",
    "    u1 = layers.Concatenate()([u1, c3])  # Skip connection\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u2 = layers.UpSampling2D((2, 2))(c5)\n",
    "    u2 = layers.Concatenate()([u2, c2])  # Skip connection\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u3 = layers.UpSampling2D((2, 2))(c6)\n",
    "    u3 = layers.Concatenate()([u3, c1])  # Skip connection\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(c7)  # For multi-class segmentation\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and show the result\n",
    "index = np.random.randint(0, len(X_val))\n",
    "test_img = X_val[index]\n",
    "true_mask = y_val[index]\n",
    "\n",
    "# Show the test & true mask\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_img)\n",
    "plt.title(\"Test Image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(true_mask.squeeze(), cmap=\"jet\")\n",
    "plt.title(\"True Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct input shape for prediction\n",
    "predicted_mask = model.predict(test_img[np.newaxis, ...])[0]\n",
    "predicted_mask = np.argmax(predicted_mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(test_img)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(true_mask.squeeze(), cmap=\"jet\")\n",
    "ax[1].set_title(\"True Mask\")\n",
    "ax[2].imshow(predicted_mask, cmap=\"jet\")\n",
    "ax[2].set_title(\"Predicted Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "meta_data = pd.read_csv(DATASET + \"/metadata.csv\")\n",
    "\n",
    "print(meta_data.head())\n",
    "# Perform 85/15 split for train / test\n",
    "test = meta_data.sample(frac=0.15, random_state=42)\n",
    "train = meta_data.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = pd.read_csv(DATASET + '/labels_class_dict.csv')\n",
    "# Get class names\n",
    "class_names = class_dict['class_names'].tolist()\n",
    "# Get class RGB values\n",
    "class_rgb_values = class_dict[['r','g','b']].values.tolist()\n",
    "\n",
    "print('All dataset classes and their corresponding RGB values in labels:')\n",
    "print('Class Names: ', class_names)\n",
    "print('Class RGB values: ', class_rgb_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
